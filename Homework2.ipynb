{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1:\n",
    "\n",
    "1. \"A random variable is discrete if its support is countable and there exists an associated probability density function (pdf)\"\n",
    "FALSE - Since discrete random variables have probability mass functions (pmf), not probability density functions (pdf). PDFs are usually used with continuous random variables.\n",
    "\n",
    "2. \"Probability mass functions have a lower bound of 0 and an upper bound of 1\"\n",
    "TRUE - PMFs must be non-negative and cannot exceed a value of 1.\n",
    "\n",
    "3. \"The set of all possible realizations of a random variable is called its probability density\"\n",
    "FALSE - This description is used as the support of the random variable. The probability density is a function that describes the relative likelihood of different outcomes.\n",
    "\n",
    "4. \"The expected value of a discrete random variable is always part of its support\"\n",
    "FALSE - The expected value can fall between possible values. For example, a fair coin has E[X] = 0.5 (for 50 50 chance), but the support would be {0,1}.\n",
    "\n",
    "5. \"Continuous random variables are functions which map points from the sample space to the real numbers\"\n",
    "TRUE - This is a correct definition of a continuous random variable.\n",
    "\n",
    "6. \"We can formulate most parametric Bayesian models as a generative process, by which we first sample from the likelihood and then use the synthetic data point to sample from the prior\"\n",
    "FALSE - In a generative process, Step one is first sampling from the prior distribution of parameters, then use those parameters to sample from the likelihood to generate data. The order is just reversed.\n",
    "\n",
    "7. \"The Bayesian posterior p(θ | y) for continuous parameter vectors θ ∈ RD is just another density function. That means, its integral R p(θ | Y = y) dθ̸ = 1 for some y\"\n",
    "FALSE - The posterior is a density function, but it must integrate to 1 for all y. The statement incorrectly says there exists some y where the integral doesn't equal 1.\n",
    "\n",
    "8. \"Each realization of a continuous random variable has a probability of zero\"\n",
    "TRUE - Individual points in a continuous distribution have probability zero; probability is only defined for intervals.\n",
    "\n",
    "In conclusion, statements 1, 3, 4, 6, and 7 are false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2:\n",
    "g(X) = +1% with prob 0.8 since the probability of the market going up is is 80%. With oil rising by 1%.\n",
    "g(X) = -10% with prob 0.2 since the probability of the market going down is 20%. With oil dropping by 10%.\n",
    "\n",
    "E[g(X)] = (0.01 x 0.8) + (-0.10 x 0.2)\n",
    "= 0.008 - 0.02\n",
    "= -0.012\n",
    "= -1.2%\n",
    "\n",
    "Based on the expectation, one should not invest, since the return is negative (-1.2%).\n",
    "FOr minimal probability p:\n",
    "P is prob of going up, then 1-p is prob of going down.\n",
    "0.01p + (-0.10)(1-p) > 0\n",
    "0.01p - 0.10 + 0.10p > 0\n",
    "0.11p - 0.10 > 0\n",
    "0.11p > 0.10\n",
    "p > 0.909 or 90.9%"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
